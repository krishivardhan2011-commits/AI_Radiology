{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "pVBSMEuJYQ2s",
        "outputId": "73c5a4f3-7504-4d8c-b36a-20fc923b8a4c"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchxrayvision'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1308438718.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchxrayvision\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchxrayvision'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchxrayvision as xrv\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load pretrained DenseNet model trained on chest X-rays\n",
        "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DiG4zwTYafF"
      },
      "outputs": [],
      "source": [
        "!pip install torchxrayvision --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-ej6LaSYpKS"
      },
      "outputs": [],
      "source": [
        "!pip install torchxrayvision --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "C7FU5t1CY_EU",
        "outputId": "f029a6c7-3c64-47a8-f12f-84c27aedd71c"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchxrayvision'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4235081175.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchxrayvision\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TorchXRayVision working ✅\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchxrayvision'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torchxrayvision as xrv\n",
        "print(\"TorchXRayVision working ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7STMQYyOZBKQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "IyUiFPQwZFoD",
        "outputId": "d68af512-f320-42ca-b06c-6d76cfa2b252"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dda1da94-ca9b-4a82-8791-3c3019846216\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dda1da94-ca9b-4a82-8791-3c3019846216\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1364939564.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    166\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    170\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "uploaded = files.upload()\n",
        "img_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Load X-ray as grayscale\n",
        "img = Image.open(img_path).convert(\"L\")\n",
        "\n",
        "# Transform for model\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "img = transform(img).unsqueeze(0)\n",
        "\n",
        "print(\"Image loaded and ready ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j-rCBIELZT1h"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchxrayvision as xrv\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = model(img)\n",
        "\n",
        "diseases = xrv.datasets.default_pathologies\n",
        "\n",
        "results = {}\n",
        "for i, d in enumerate(diseases):\n",
        "    results[d] = float(preds[0][i])\n",
        "\n",
        "# Sort by probability\n",
        "sorted_results = dict(sorted(results.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "print(\"\\nTop predicted findings:\\n\")\n",
        "for k, v in list(sorted_results.items())[:10]:\n",
        "    print(f\"{k}: {v:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4YO85BIPaMcu"
      },
      "outputs": [],
      "source": [
        "def generate_radiology_report(preds_dict, clinical_text, threshold=0.4):\n",
        "    findings = []\n",
        "    impression = []\n",
        "\n",
        "    for disease, prob in preds_dict.items():\n",
        "        if prob > threshold:\n",
        "            if disease == \"Effusion\":\n",
        "                findings.append(\"Blunting of the costophrenic angle suggesting pleural effusion.\")\n",
        "                impression.append(\"Pleural effusion likely present.\")\n",
        "            elif disease == \"Cardiomegaly\":\n",
        "                findings.append(\"Cardiac silhouette appears enlarged.\")\n",
        "                impression.append(\"Findings consistent with cardiomegaly.\")\n",
        "            elif disease == \"Atelectasis\":\n",
        "                findings.append(\"Linear opacities suggesting atelectasis.\")\n",
        "                impression.append(\"Possible atelectasis.\")\n",
        "            elif disease == \"Pneumonia\":\n",
        "                findings.append(\"Patchy airspace opacity suspicious for pneumonia.\")\n",
        "                impression.append(\"Pneumonia cannot be excluded.\")\n",
        "            elif disease == \"Consolidation\":\n",
        "                findings.append(\"Focal consolidation noted in lung field.\")\n",
        "                impression.append(\"Consolidation likely.\")\n",
        "            elif disease == \"Edema\":\n",
        "                findings.append(\"Diffuse interstitial markings suggesting pulmonary edema.\")\n",
        "                impression.append(\"Pulmonary edema suspected.\")\n",
        "\n",
        "    if len(findings) == 0:\n",
        "        findings.append(\"No acute cardiopulmonary abnormality detected.\")\n",
        "        impression.append(\"Study appears within normal limits.\")\n",
        "\n",
        "    report = f\"\"\"\n",
        "CLINICAL INDICATION:\n",
        "{clinical_text}\n",
        "\n",
        "FINDINGS:\n",
        "{\" \".join(findings)}\n",
        "\n",
        "IMPRESSION:\n",
        "{\" \".join(impression)}\n",
        "\"\"\"\n",
        "    return report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aCwlzaENaRbu"
      },
      "outputs": [],
      "source": [
        "# Use top predictions dictionary (from earlier cell)\n",
        "clinical_text = \"65 year old patient with cough and shortness of breath\"\n",
        "\n",
        "report = generate_radiology_report(sorted_results, clinical_text)\n",
        "\n",
        "print(\"\\n===== GENERATED RADIOLOGY REPORT =====\\n\")\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VKBOeQvCaTWP"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "uploaded = files.upload()\n",
        "img_path = list(uploaded.keys())[0]\n",
        "\n",
        "img = Image.open(img_path).convert(\"L\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "img = transform(img).unsqueeze(0)\n",
        "\n",
        "print(\"New image loaded ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PQzFS7LKeSVZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchxrayvision as xrv\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = model(img)\n",
        "\n",
        "diseases = xrv.datasets.default_pathologies\n",
        "\n",
        "results = {}\n",
        "for i, d in enumerate(diseases):\n",
        "    results[d] = float(preds[0][i])\n",
        "\n",
        "sorted_results = dict(sorted(results.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "print(\"\\nTop predicted findings:\\n\")\n",
        "for k, v in list(sorted_results.items())[:10]:\n",
        "    print(f\"{k}: {v:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j85yicxXeXeo"
      },
      "outputs": [],
      "source": [
        "clinical_text = input(\"Enter clinical indication: \")\n",
        "\n",
        "report = generate_radiology_report(sorted_results, clinical_text)\n",
        "\n",
        "print(\"\\n===== GENERATED RADIOLOGY REPORT =====\\n\")\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PN1lBRnwecQX"
      },
      "outputs": [],
      "source": [
        "Get real chest X-ray sample set\n",
        "\n",
        "Add confidence scores\n",
        "\n",
        "Show heatmap (where model looked)\n",
        "\n",
        "Improve medical wording\n",
        "\n",
        "Make automatic batch testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SDMZsECJfESL"
      },
      "outputs": [],
      "source": [
        "!mkdir xrays\n",
        "!wget -q https://raw.githubusercontent.com/mlmed/torchxrayvision/master/tests/assets/nih_sample.png -O xrays/xray1.png\n",
        "!wget -q https://raw.githubusercontent.com/mlmed/torchxrayvision/master/tests/assets/nih_sample2.png -O xrays/xray2.png\n",
        "!wget -q https://raw.githubusercontent.com/mlmed/torchxrayvision/master/tests/assets/nih_sample3.png -O xrays/xray3.png\n",
        "\n",
        "print(\"Sample X-rays downloaded ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "883zAsh7fHSH"
      },
      "outputs": [],
      "source": [
        "def show_predictions_with_confidence(preds, diseases, topk=8):\n",
        "    scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "    scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "    print(\"\\n=== Disease Confidence Scores ===\\n\")\n",
        "    for k, v in list(scores.items())[:topk]:\n",
        "        print(f\"{k:20s} : {v:.3f}\")\n",
        "\n",
        "    return scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z-Xz7qjFfNz2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def generate_heatmap(model, img):\n",
        "    img.requires_grad = True\n",
        "    output = model(img)\n",
        "    score = output.max()\n",
        "    score.backward()\n",
        "\n",
        "    gradients = img.grad.data[0].numpy()[0]\n",
        "    heatmap = np.maximum(gradients, 0)\n",
        "    heatmap = heatmap / (heatmap.max() + 1e-8)\n",
        "\n",
        "    plt.imshow(heatmap, cmap='jet')\n",
        "    plt.title(\"Model Attention Heatmap\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ktvQH4hofP5G"
      },
      "outputs": [],
      "source": [
        "def generate_better_report(preds_dict, clinical_text, threshold=0.4):\n",
        "    findings = []\n",
        "    impression = []\n",
        "\n",
        "    for disease, prob in preds_dict.items():\n",
        "        if prob > threshold:\n",
        "            severity = \"mild\"\n",
        "            if prob > 0.7:\n",
        "                severity = \"moderate\"\n",
        "            if prob > 0.85:\n",
        "                severity = \"significant\"\n",
        "\n",
        "            findings.append(f\"{severity.capitalize()} radiographic features of {disease.lower()} observed.\")\n",
        "            impression.append(f\"{disease} is {severity}ly likely.\")\n",
        "\n",
        "    if not findings:\n",
        "        findings.append(\"Lungs are clear. No focal consolidation, pleural effusion, or pneumothorax.\")\n",
        "        impression.append(\"No acute cardiopulmonary abnormality.\")\n",
        "\n",
        "    report = f\"\"\"\n",
        "CLINICAL INDICATION:\n",
        "{clinical_text}\n",
        "\n",
        "FINDINGS:\n",
        "{\" \".join(findings)}\n",
        "\n",
        "IMPRESSION:\n",
        "{\" \".join(impression)}\n",
        "\"\"\"\n",
        "    return report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "73zwcMYGfR1G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torchxrayvision as xrv\n",
        "\n",
        "def batch_test(folder=\"xrays\"):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    diseases = xrv.datasets.default_pathologies\n",
        "\n",
        "    for file in os.listdir(folder):\n",
        "        path = os.path.join(folder, file)\n",
        "\n",
        "        img = Image.open(path).convert(\"L\")\n",
        "        img_t = transform(img).unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model(img_t)\n",
        "\n",
        "        scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "        scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "        report = generate_better_report(scores, \"Automated batch test\")\n",
        "\n",
        "        print(\"\\n==============================\")\n",
        "        print(\"Image:\", file)\n",
        "        print(\"==============================\")\n",
        "        print(report)\n",
        "\n",
        "batch_test(\"xrays\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GuNwCh7MfTiG"
      },
      "outputs": [],
      "source": [
        "!rm -rf xrays\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4Olub52ffsKG"
      },
      "outputs": [],
      "source": [
        "!mkdir xrays\n",
        "!wget -O xrays/xray1.png https://github.com/mlmed/torchxrayvision/raw/master/tests/assets/nih_sample.png\n",
        "!wget -O xrays/xray2.png https://github.com/mlmed/torchxrayvision/raw/master/tests/assets/nih_sample2.png\n",
        "!wget -O xrays/xray3.png https://github.com/mlmed/torchxrayvision/raw/master/tests/assets/nih_sample3.png\n",
        "\n",
        "print(\"Real X-ray images downloaded successfully ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2h4NV5Ggft0l"
      },
      "outputs": [],
      "source": [
        "batch_test(\"xrays\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WYzv-e45fw41"
      },
      "outputs": [],
      "source": [
        "!rm -rf xrays\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aQQDVMdmf9D1"
      },
      "outputs": [],
      "source": [
        "!mkdir xrays\n",
        "\n",
        "!wget -q --show-progress https://github.com/mlmed/torchxrayvision/raw/master/tests/assets/nih_sample.png?raw=true -O xrays/xray1.png\n",
        "!wget -q --show-progress https://github.com/mlmed/torchxrayvision/raw/master/tests/assets/nih_sample2.png?raw=true -O xrays/xray2.png\n",
        "!wget -q --show-progress https://github.com/mlmed/torchxrayvision/raw/master/tests/assets/nih_sample3.png?raw=true -O xrays/xray3.png\n",
        "\n",
        "print(\"X-ray images downloaded correctly ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J4dpjqELgA1l"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "display(Image.open(\"xrays/xray1.png\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yqEOTWXdgC0E"
      },
      "outputs": [],
      "source": [
        "!rm -rf xrays\n",
        "!mkdir xrays\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Vi93BPNUgPAE"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bYWtcz2Pg3L0"
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "\n",
        "for f in uploaded.keys():\n",
        "    shutil.move(f, f\"xrays/{f}\")\n",
        "\n",
        "print(\"Images moved to xrays/ folder ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j_CWZfq3g_ZT"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "for f in os.listdir(\"xrays\"):\n",
        "    display(Image.open(f\"xrays/{f}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8sT3_vYQhA8z"
      },
      "outputs": [],
      "source": [
        "batch_test(\"xrays\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "veda560_hEJD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def gradcam(model, img):\n",
        "    model.eval()\n",
        "    img = img.clone().detach()\n",
        "    img.requires_grad_(True)\n",
        "\n",
        "    output = model(img)\n",
        "    score = output.max()\n",
        "    score.backward()\n",
        "\n",
        "    gradients = img.grad[0].cpu().numpy()[0]\n",
        "    heatmap = np.maximum(gradients, 0)\n",
        "    heatmap /= (heatmap.max() + 1e-8)\n",
        "\n",
        "    plt.imshow(heatmap, cmap='jet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U3IF714zhMiz"
      },
      "outputs": [],
      "source": [
        "gradcam(model, img_t)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gRdaoaBwhSBj"
      },
      "outputs": [],
      "source": [
        "def generate_realistic_report(preds_dict, clinical_text, threshold=0.45):\n",
        "    findings = []\n",
        "    impression = []\n",
        "    negatives = []\n",
        "\n",
        "    important = [\"Effusion\", \"Cardiomegaly\", \"Pneumonia\", \"Consolidation\", \"Edema\", \"Atelectasis\"]\n",
        "\n",
        "    for disease, prob in preds_dict.items():\n",
        "        if disease not in important:\n",
        "            continue\n",
        "\n",
        "        if prob > threshold:\n",
        "            if prob > 0.8:\n",
        "                severity = \"significant\"\n",
        "            elif prob > 0.6:\n",
        "                severity = \"moderate\"\n",
        "            else:\n",
        "                severity = \"mild\"\n",
        "\n",
        "            findings.append(f\"{severity.capitalize()} radiographic evidence of {disease.lower()}.\")\n",
        "            impression.append(f\"{disease} is {severity}ly likely.\")\n",
        "        else:\n",
        "            negatives.append(disease.lower())\n",
        "\n",
        "    if not findings:\n",
        "        findings.append(\"Lungs are clear without focal consolidation, effusion, or pneumothorax.\")\n",
        "        impression.append(\"No acute cardiopulmonary abnormality.\")\n",
        "\n",
        "    report = f\"\"\"\n",
        "CLINICAL INDICATION:\n",
        "{clinical_text}\n",
        "\n",
        "FINDINGS:\n",
        "{\" \".join(findings)}\n",
        "\n",
        "NEGATIVE FINDINGS:\n",
        "No clear radiographic evidence of {\", \".join(negatives[:5])}.\n",
        "\n",
        "IMPRESSION:\n",
        "{\" \".join(impression)}\n",
        "\"\"\"\n",
        "    return report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lM2sHRj_hUMy"
      },
      "outputs": [],
      "source": [
        "def generate_realistic_report(preds_dict, clinical_text, threshold=0.45):\n",
        "    findings = []\n",
        "    impression = []\n",
        "    negatives = []\n",
        "\n",
        "    important = [\"Effusion\", \"Cardiomegaly\", \"Pneumonia\", \"Consolidation\", \"Edema\", \"Atelectasis\"]\n",
        "\n",
        "    for disease, prob in preds_dict.items():\n",
        "        if disease not in important:\n",
        "            continue\n",
        "\n",
        "        if prob > threshold:\n",
        "            if prob > 0.8:\n",
        "                severity = \"significant\"\n",
        "            elif prob > 0.6:\n",
        "                severity = \"moderate\"\n",
        "            else:\n",
        "                severity = \"mild\"\n",
        "\n",
        "            findings.append(f\"{severity.capitalize()} radiographic evidence of {disease.lower()}.\")\n",
        "            impression.append(f\"{disease} is {severity}ly likely.\")\n",
        "        else:\n",
        "            negatives.append(disease.lower())\n",
        "\n",
        "    if not findings:\n",
        "        findings.append(\"Lungs are clear without focal consolidation, effusion, or pneumothorax.\")\n",
        "        impression.append(\"No acute cardiopulmonary abnormality.\")\n",
        "\n",
        "    report = f\"\"\"\n",
        "CLINICAL INDICATION:\n",
        "{clinical_text}\n",
        "\n",
        "FINDINGS:\n",
        "{\" \".join(findings)}\n",
        "\n",
        "NEGATIVE FINDINGS:\n",
        "No clear radiographic evidence of {\", \".join(negatives[:5])}.\n",
        "\n",
        "IMPRESSION:\n",
        "{\" \".join(impression)}\n",
        "\"\"\"\n",
        "    return report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kcNLgZoYhggq"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "img_path = list(uploaded.keys())[0]\n",
        "print(\"Uploaded:\", img_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IZS0vyBdhi9z"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "img = Image.open(img_path).convert(\"L\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "img_t = transform(img).unsqueeze(0)\n",
        "print(\"Image processed ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_yfPjIH8hm8y"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    preds = model(img_t)\n",
        "\n",
        "scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "print(\"\\nTop Predictions:\\n\")\n",
        "for k, v in list(scores.items())[:8]:\n",
        "    print(f\"{k:20s}: {v:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xTW8aVaXhpDy"
      },
      "outputs": [],
      "source": [
        "clinical_text = input(\"Enter clinical indication: \")\n",
        "\n",
        "report = generate_realistic_report(scores, clinical_text)\n",
        "print(\"\\n===== RADIOLOGY REPORT =====\\n\")\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1HHWR7Q1hrCi"
      },
      "outputs": [],
      "source": [
        "gradcam(model, img_t)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wd6MI8OahwNC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "def real_gradcam(model, img):\n",
        "    model.eval()\n",
        "\n",
        "    # Get last conv layer\n",
        "    target_layer = model.features[-1]\n",
        "\n",
        "    activations = []\n",
        "    gradients = []\n",
        "\n",
        "    def forward_hook(module, inp, out):\n",
        "        activations.append(out)\n",
        "\n",
        "    def backward_hook(module, grad_in, grad_out):\n",
        "        gradients.append(grad_out[0])\n",
        "\n",
        "    # Register hooks\n",
        "    fh = target_layer.register_forward_hook(forward_hook)\n",
        "    bh = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    # Forward\n",
        "    output = model(img)\n",
        "    class_idx = output.argmax()\n",
        "    score = output[0, class_idx]\n",
        "\n",
        "    # Backward\n",
        "    model.zero_grad()\n",
        "    score.backward()\n",
        "\n",
        "    # Get data\n",
        "    grads = gradients[0].detach().cpu().numpy()[0]\n",
        "    acts = activations[0].detach().cpu().numpy()[0]\n",
        "\n",
        "    weights = np.mean(grads, axis=(1, 2))\n",
        "    cam = np.zeros(acts.shape[1:], dtype=np.float32)\n",
        "\n",
        "    for i, w in enumerate(weights):\n",
        "        cam += w * acts[i]\n",
        "\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cam / (cam.max() + 1e-8)\n",
        "\n",
        "    # Resize to image size\n",
        "    cam = cv2.resize(cam, (224, 224))\n",
        "\n",
        "    # Convert original image\n",
        "    img_np = img.detach().cpu().numpy()[0][0]\n",
        "\n",
        "    # Overlay heatmap\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(img_np, cmap=\"gray\")\n",
        "    plt.imshow(cam, cmap=\"jet\", alpha=0.4)\n",
        "    plt.title(\"Grad-CAM (Model Focus)\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    # Remove hooks\n",
        "    fh.remove()\n",
        "    bh.remove()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DfDRVhAoiH-j"
      },
      "outputs": [],
      "source": [
        "real_gradcam(model, img_t)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HnReUYfqiKDR"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "kaggle_dict = {\n",
        "    \"username\": \"krishiket\",\n",
        "    \"key\": \"KGAT_d18afec69c0e78ca315bfd00ee871f08\"\n",
        "}\n",
        "\n",
        "with open(\"kaggle.json\", \"w\") as f:\n",
        "    json.dump(kaggle_dict, f)\n",
        "\n",
        "print(\"kaggle.json created manually ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y6nXKYEo-Pnl"
      },
      "outputs": [],
      "source": [
        " !mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"Kaggle setup complete ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jaiEbkYTD6ds"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DCklFndzD8BK"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d raddar/chest-xrays-indiana-university\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AV479M1QD90a"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d raddar/chest-xrays-indiana-university\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pJtlDJtpElTJ"
      },
      "outputs": [],
      "source": [
        "!pip install -q kagglehub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ng2Klue6FnRt"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"raddar/chest-xrays-indiana-university\")\n",
        "\n",
        "print(\"Dataset downloaded to:\", path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vkp8Wn7yFqaY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.listdir(path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bo493PmRHJ_F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "print(os.listdir(path))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IQ-g5BzHHqA0"
      },
      "outputs": [],
      "source": [
        "for root, dirs, files in os.walk(path):\n",
        "    for f in files[:5]:\n",
        "        print(os.path.join(root, f))\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VPhmSmHVHteU"
      },
      "outputs": [],
      "source": [
        "for root, dirs, files in os.walk(path):\n",
        "    if len(files) > 0:\n",
        "        print(\"FOLDER:\", root)\n",
        "        print(\"Sample files:\", files[:5])\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jCLrrKLGH_xU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "img_root = os.path.join(path, \"images\")\n",
        "print(\"Inside images folder:\", os.listdir(img_root)[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3qLC_hCxIvyD"
      },
      "outputs": [],
      "source": [
        "img_folder = os.path.join(img_root, \"images_normalized\")\n",
        "print(\"Sample images:\", os.listdir(img_folder)[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WikRF3LXIyLy"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_path = os.path.join(img_folder, os.listdir(img_folder)[0])\n",
        "print(\"Loading:\", img_path)\n",
        "\n",
        "img = Image.open(img_path).convert(\"L\")\n",
        "\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"IU Chest X-ray Sample\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "09JLEp1BI3Rh"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "img_t = transform(img).unsqueeze(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = model(img_t)\n",
        "\n",
        "scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "for k, v in list(scores.items())[:8]:\n",
        "    print(f\"{k:20s}: {v:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dPWb1D_DI6ny"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchxrayvision as xrv\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yZ3tagVhJNkl"
      },
      "outputs": [],
      "source": [
        "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "model.eval()\n",
        "\n",
        "diseases = xrv.datasets.default_pathologies\n",
        "print(\"Model ready ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A5SYYygWJT-B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchxrayvision as xrv\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Load model\n",
        "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "model.eval()\n",
        "\n",
        "# Disease labels\n",
        "diseases = xrv.datasets.default_pathologies\n",
        "\n",
        "print(\"Model ready ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zAHsVrIAJgDR"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchxrayvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FjBG0RnyJuZB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchxrayvision as xrv\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "model.eval()\n",
        "\n",
        "diseases = xrv.datasets.default_pathologies\n",
        "\n",
        "print(\"Model ready ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tqJG1EyiJxTF"
      },
      "outputs": [],
      "source": [
        "img_t = transform(img).unsqueeze(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = model(img_t)\n",
        "\n",
        "scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "for k, v in list(scores.items())[:8]:\n",
        "    print(f\"{k:20s}: {v:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "euUewxeRJz5R"
      },
      "outputs": [],
      "source": [
        "report = generate_realistic_report(scores, \"Patient from IU Chest X-ray dataset\")\n",
        "\n",
        "print(\"\\n===== AI RADIOLOGY REPORT (IU DATASET) =====\\n\")\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mA8EyxVKOq7p"
      },
      "outputs": [],
      "source": [
        "report = generate_realistic_report(scores, \"Patient from IU Chest X-ray dataset\")\n",
        "\n",
        "print(\"\\n===== AI RADIOLOGY REPORT (IU DATASET) =====\\n\")\n",
        "print(report)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cifCMhCNOy8P"
      },
      "outputs": [],
      "source": [
        "def generate_realistic_report(preds_dict, clinical_text, threshold=0.45):\n",
        "    findings = []\n",
        "    impression = []\n",
        "    negatives = []\n",
        "\n",
        "    important = [\"Effusion\", \"Cardiomegaly\", \"Pneumonia\", \"Consolidation\", \"Edema\", \"Atelectasis\"]\n",
        "\n",
        "    for disease, prob in preds_dict.items():\n",
        "        if disease not in important:\n",
        "            continue\n",
        "\n",
        "        if prob > threshold:\n",
        "            if prob > 0.8:\n",
        "                severity = \"significant\"\n",
        "            elif prob > 0.6:\n",
        "                severity = \"moderate\"\n",
        "            else:\n",
        "                severity = \"mild\"\n",
        "\n",
        "            findings.append(f\"{severity.capitalize()} radiographic evidence of {disease.lower()}.\")\n",
        "            impression.append(f\"{disease} is {severity}ly likely.\")\n",
        "        else:\n",
        "            negatives.append(disease.lower())\n",
        "\n",
        "    if not findings:\n",
        "        findings.append(\"Lungs are clear without focal consolidation, effusion, or pneumothorax.\")\n",
        "        impression.append(\"No acute cardiopulmonary abnormality.\")\n",
        "\n",
        "    report = f\"\"\"\n",
        "CLINICAL INDICATION:\n",
        "{clinical_text}\n",
        "\n",
        "FINDINGS:\n",
        "{\" \".join(findings)}\n",
        "\n",
        "NEGATIVE FINDINGS:\n",
        "No clear radiographic evidence of {\", \".join(negatives[:5])}.\n",
        "\n",
        "IMPRESSION:\n",
        "{\" \".join(impression)}\n",
        "\"\"\"\n",
        "    return report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6Mn2HummPFhM"
      },
      "outputs": [],
      "source": [
        "report = generate_realistic_report(scores, \"Patient from IU Chest X-ray dataset\")\n",
        "\n",
        "print(\"\\n===== AI RADIOLOGY REPORT (IU DATASET) =====\\n\")\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-uPXYLxNPHvo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "reports_path = os.path.join(path, \"indiana_reports.csv\")\n",
        "df_reports = pd.read_csv(reports_path)\n",
        "\n",
        "print(\"Columns:\", df_reports.columns)\n",
        "print(\"\\nSample row:\\n\")\n",
        "print(df_reports.iloc[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NBqHFor9PrfJ"
      },
      "outputs": [],
      "source": [
        "print(\"\\n===== REAL RADIOLOGIST REPORT =====\\n\")\n",
        "\n",
        "print(\"FINDINGS:\\n\")\n",
        "print(df_reports.iloc[0][\"findings\"])\n",
        "\n",
        "print(\"\\nIMPRESSION:\\n\")\n",
        "print(df_reports.iloc[0][\"impression\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "doDo6t6uPtrH"
      },
      "outputs": [],
      "source": [
        "1. Make AI learn writing style from real IU reports (BIG improvement)\n",
        "2. Improve disease reasoning (better medical accuracy)\n",
        "3. Integrate your Cognitive Modules (PRO-FA, MIX-MLP, RCTA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OQjKJxpAP8QH"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z0-9., ]\", \"\", text)\n",
        "    return text\n",
        "\n",
        "df_reports[\"findings_clean\"] = df_reports[\"findings\"].apply(clean_text)\n",
        "df_reports[\"impression_clean\"] = df_reports[\"impression\"].apply(clean_text)\n",
        "\n",
        "print(\"Cleaned ✔\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RSvjISwwQDXq"
      },
      "outputs": [],
      "source": [
        "phrase_bank_findings = []\n",
        "phrase_bank_impression = []\n",
        "\n",
        "for i in range(min(300, len(df_reports))):\n",
        "    f = df_reports.iloc[i][\"findings_clean\"]\n",
        "    im = df_reports.iloc[i][\"impression_clean\"]\n",
        "\n",
        "    if len(f) > 30:\n",
        "        phrase_bank_findings.append(f)\n",
        "    if len(im) > 20:\n",
        "        phrase_bank_impression.append(im)\n",
        "\n",
        "print(\"Phrase bank ready ✔\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "grydWU-bQFqm"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_learned_report(preds_dict, clinical_text, threshold=0.45):\n",
        "    findings = []\n",
        "    impression = []\n",
        "\n",
        "    important = [\"Effusion\", \"Cardiomegaly\", \"Pneumonia\", \"Consolidation\", \"Edema\", \"Atelectasis\"]\n",
        "\n",
        "    for disease, prob in preds_dict.items():\n",
        "        if disease not in important:\n",
        "            continue\n",
        "\n",
        "        if prob > threshold:\n",
        "            severity = \"mild\"\n",
        "            if prob > 0.7:\n",
        "                severity = \"moderate\"\n",
        "            if prob > 0.85:\n",
        "                severity = \"severe\"\n",
        "\n",
        "            findings.append(f\"{severity} features of {disease.lower()} noted.\")\n",
        "            impression.append(f\"{disease.lower()} likely.\")\n",
        "\n",
        "    if not findings:\n",
        "        findings.append(\"lungs are clear without acute cardiopulmonary abnormality.\")\n",
        "        impression.append(\"no acute abnormality detected.\")\n",
        "\n",
        "    # Add real style sentence\n",
        "    if len(phrase_bank_findings) > 0:\n",
        "        findings.append(random.choice(phrase_bank_findings))\n",
        "    if len(phrase_bank_impression) > 0:\n",
        "        impression.append(random.choice(phrase_bank_impression))\n",
        "\n",
        "    report = f\"\"\"\n",
        "CLINICAL INDICATION:\n",
        "{clinical_text}\n",
        "\n",
        "FINDINGS:\n",
        "{\" \".join(findings)}\n",
        "\n",
        "IMPRESSION:\n",
        "{\" \".join(impression)}\n",
        "\"\"\"\n",
        "    return report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dyda0AQSQHYW"
      },
      "outputs": [],
      "source": [
        "def improve_reasoning(scores):\n",
        "    # Example medical reasoning rules\n",
        "\n",
        "    if scores.get(\"Edema\", 0) > 0.6 and scores.get(\"Cardiomegaly\", 0) > 0.5:\n",
        "        scores[\"Heart Failure Pattern\"] = 0.9\n",
        "\n",
        "    if scores.get(\"Consolidation\", 0) > 0.5 and scores.get(\"Pneumonia\", 0) > 0.4:\n",
        "        scores[\"Infectious Pattern\"] = 0.85\n",
        "\n",
        "    if scores.get(\"Effusion\", 0) > 0.6 and scores.get(\"Atelectasis\", 0) > 0.4:\n",
        "        scores[\"Pleural Disease Pattern\"] = 0.8\n",
        "\n",
        "    return scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x8mpfJS-QJgW"
      },
      "outputs": [],
      "source": [
        "scores = improve_reasoning(scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sMNiGkg4QPNn"
      },
      "outputs": [],
      "source": [
        "def pro_fa_simulation(img):\n",
        "    organ_feature = img.mean().item()\n",
        "    region_feature = img[:, :, 80:150, 80:150].mean().item()\n",
        "    pixel_feature = img.std().item()\n",
        "    return [organ_feature, region_feature, pixel_feature]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tnhvK2KiQQ33"
      },
      "outputs": [],
      "source": [
        "def mix_mlp_simulation(scores):\n",
        "    # Combine disease features\n",
        "    confidence = sum(scores.values()) / len(scores)\n",
        "    return confidence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nUP0Zr7mQTSH"
      },
      "outputs": [],
      "source": [
        "def rcta_simulation(img, clinical_text, scores):\n",
        "    visual = pro_fa_simulation(img)\n",
        "    diagnosis_conf = mix_mlp_simulation(scores)\n",
        "\n",
        "    context_score = len(clinical_text) * 0.01\n",
        "    final_conf = (sum(visual) + diagnosis_conf + context_score) / 3\n",
        "\n",
        "    return final_conf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CDz3d06LQVfW"
      },
      "outputs": [],
      "source": [
        "final_confidence = rcta_simulation(img_t, \"Patient with cough\", scores)\n",
        "print(\"Cognitive confidence:\", final_confidence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J_uziOXqQZ2W"
      },
      "outputs": [],
      "source": [
        "scores = improve_reasoning(scores)\n",
        "\n",
        "report = generate_learned_report(scores, \"Patient with cough and fever\")\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8EQHdXdoQb4Y"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rs8-Qmh_QrzX"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torchxrayvision as xrv\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Load model once\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "    model.eval()\n",
        "    diseases = xrv.datasets.default_pathologies\n",
        "    return model, diseases\n",
        "\n",
        "model, diseases = load_model()\n",
        "\n",
        "# Simple report generator\n",
        "def generate_report(scores):\n",
        "    findings = []\n",
        "    impression = []\n",
        "\n",
        "    for d, p in scores.items():\n",
        "        if p > 0.5:\n",
        "            findings.append(f\"{d} detected with confidence {p:.2f}\")\n",
        "            impression.append(f\"Possible {d}\")\n",
        "\n",
        "    if not findings:\n",
        "        findings.append(\"No acute abnormality detected.\")\n",
        "        impression.append(\"Normal study.\")\n",
        "\n",
        "    return f\"\"\"\n",
        "FINDINGS:\n",
        "{' '.join(findings)}\n",
        "\n",
        "IMPRESSION:\n",
        "{' '.join(impression)}\n",
        "\"\"\"\n",
        "\n",
        "st.title(\"🩺 AI Cognitive Radiology Demo\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload Chest X-ray\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    img = Image.open(uploaded_file).convert(\"L\")\n",
        "    st.image(img, caption=\"Uploaded X-ray\", use_column_width=True)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    img_t = transform(img).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model(img_t)\n",
        "\n",
        "    scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "    scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "    st.subheader(\"Top Predictions\")\n",
        "    for k, v in list(scores.items())[:5]:\n",
        "        st.write(f\"{k}: {v:.3f}\")\n",
        "\n",
        "    report = generate_report(scores)\n",
        "\n",
        "    st.subheader(\"AI Radiology Report\")\n",
        "    st.text(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pxfIxU61QvS3"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Start Streamlit\n",
        "process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\"])\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"OPEN THIS LINK 👉\", public_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VpgGu3J4Qyol"
      },
      "outputs": [],
      "source": [
        "!pkill -f streamlit\n",
        "!pkill -f ngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "43mBYk4XRnCO"
      },
      "outputs": [],
      "source": [
        "!npm install -g localtunnel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qSvWpGvlRpVU"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Start Streamlit\n",
        "process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\"])\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        "# Create public tunnel WITHOUT ngrok\n",
        "print(\"Starting public link...\")\n",
        "tunnel = subprocess.Popen([\"lt\", \"--port\", \"8501\"], stdout=subprocess.PIPE)\n",
        "\n",
        "time.sleep(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lACjmkniRt0k"
      },
      "outputs": [],
      "source": [
        "!curl ipv4.icanhazip.com\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HILGml6WRxN0"
      },
      "outputs": [],
      "source": [
        "!lt --port 8501\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F6o5jGWySWLW"
      },
      "outputs": [],
      "source": [
        "!pkill -f streamlit\n",
        "!pkill -f lt\n",
        "!pkill -f python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H_k1EsyET_7w"
      },
      "outputs": [],
      "source": [
        "!pkill -f streamlit\n",
        "!pkill -f lt\n",
        "!pkill -f python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1c7dESJpWO7e"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit torch torchvision torchxrayvision\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lxLeox40WRd9"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torchxrayvision as xrv\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "st.set_page_config(page_title=\"AI Cognitive Radiology\", layout=\"centered\")\n",
        "\n",
        "# Load model once\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "    model.eval()\n",
        "    diseases = xrv.datasets.default_pathologies\n",
        "    return model, diseases\n",
        "\n",
        "model, diseases = load_model()\n",
        "\n",
        "def generate_report(scores, clinical_text):\n",
        "    findings = []\n",
        "    impression = []\n",
        "\n",
        "    for d, p in scores.items():\n",
        "        if p > 0.5:\n",
        "            findings.append(f\"{d} detected (confidence {p:.2f})\")\n",
        "            impression.append(f\"Possible {d}\")\n",
        "\n",
        "    if not findings:\n",
        "        findings.append(\"No acute cardiopulmonary abnormality.\")\n",
        "        impression.append(\"Normal study.\")\n",
        "\n",
        "    return f\"\"\"\n",
        "CLINICAL INDICATION:\n",
        "{clinical_text}\n",
        "\n",
        "FINDINGS:\n",
        "{' '.join(findings)}\n",
        "\n",
        "IMPRESSION:\n",
        "{' '.join(impression)}\n",
        "\"\"\"\n",
        "\n",
        "st.title(\"🩺 AI Cognitive Radiology Demo\")\n",
        "\n",
        "clinical_text = st.text_input(\n",
        "    \"Clinical Indication\",\n",
        "    \"Patient with cough and fever\"\n",
        ")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload Chest X-ray\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    img = Image.open(uploaded_file).convert(\"L\")\n",
        "    st.image(img, caption=\"Uploaded X-ray\", use_column_width=True)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    img_t = transform(img).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model(img_t)\n",
        "\n",
        "    scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "    scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "    st.subheader(\"Top Predictions\")\n",
        "    for k, v in list(scores.items())[:5]:\n",
        "        st.write(f\"{k}: {v:.3f}\")\n",
        "\n",
        "    confidence = sum(scores.values()) / len(scores)\n",
        "    st.metric(\"Cognitive Confidence\", f\"{confidence:.2f}\")\n",
        "\n",
        "    report = generate_report(scores, clinical_text)\n",
        "\n",
        "    st.subheader(\"AI Radiology Report\")\n",
        "    st.text(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YHCsBvjfWk_8"
      },
      "outputs": [],
      "source": [
        "import subprocess, time\n",
        "subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\"])\n",
        "time.sleep(6)\n",
        "print(\"Streamlit started\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7fX1G1c-XBu8"
      },
      "outputs": [],
      "source": [
        "!lt --port 8501\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0RySMBZzXFl7"
      },
      "outputs": [],
      "source": [
        "!npx localtunnel --port 8501\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5gXJWHZLXzM6"
      },
      "outputs": [],
      "source": [
        "!pip install -q flask flask-ngrok torch torchvision torchxrayvision pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JDIMfXLUFHRs"
      },
      "outputs": [],
      "source": [
        "from flask import Flask\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return \"<h1>Flask is working in Colab 🚀</h1>\"\n",
        "\n",
        "app.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kQMYU3EHFLPw"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yr5Oc3X0GLbg"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def test():\n",
        "    return \"AI Cognitive Radiology is running 🚀\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=test,\n",
        "    inputs=[],\n",
        "    outputs=\"text\",\n",
        "    title=\"AI Cognitive Radiology\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4ILrrsUgGRGe"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torchxrayvision as xrv\n",
        "\n",
        "# Load model\n",
        "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "model.eval()\n",
        "diseases = xrv.datasets.default_pathologies\n",
        "\n",
        "# Image transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "def predict_xray(img):\n",
        "    img = img.convert(\"RGB\")\n",
        "    img_t = transform(img).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model(img_t)[0]\n",
        "\n",
        "    scores = {diseases[i]: float(preds[i]) for i in range(len(diseases))}\n",
        "    scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "    top5 = \"\\n\".join([f\"{k}: {v:.3f}\" for k,v in list(scores.items())[:5]])\n",
        "    return top5\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict_xray,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"AI Cognitive Radiology — X-ray Analyzer\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Kg6q-qPMHOzk"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torchxrayvision as xrv\n",
        "\n",
        "# Load model\n",
        "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "model.eval()\n",
        "diseases = xrv.datasets.default_pathologies\n",
        "\n",
        "# Image transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "def predict_xray(img):\n",
        "    img = img.convert(\"RGB\")\n",
        "    img_t = transform(img).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model(img_t)[0]\n",
        "\n",
        "    scores = {diseases[i]: float(preds[i]) for i in range(len(diseases))}\n",
        "    scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "    top5 = \"\\n\".join([f\"{k}: {v:.3f}\" for k,v in list(scores.items())[:5]])\n",
        "    return top5\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict_xray,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"AI Cognitive Radiology — X-ray Analyzer\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GWhQaPhAHdwx"
      },
      "outputs": [],
      "source": [
        "pip install streamlit torch torchvision pillow torchxrayvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DRjSWKhGLkB8"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import sys\n",
        "\n",
        "def animated_generate_process(text=\"Generating Cognitive Report\"):\n",
        "    frames = [\"⠋\",\"⠙\",\"⠹\",\"⠸\",\"⠼\",\"⠴\",\"⠦\",\"⠧\",\"⠇\",\"⠏\"]\n",
        "    for i in range(30):\n",
        "        frame = frames[i % len(frames)]\n",
        "        sys.stdout.write(f\"\\r{frame} {text}...\")\n",
        "        sys.stdout.flush()\n",
        "        time.sleep(0.08)\n",
        "    print(\"\\r✔ Generation Complete!          \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6bw_92H9MFTe"
      },
      "outputs": [],
      "source": [
        "def pulse_effect():\n",
        "    for i in range(3):\n",
        "        print(\"⚡ Cognitive Engine Activating\" + \".\" * (i+1))\n",
        "        time.sleep(0.3)\n",
        "\n",
        "pulse_effect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oNdB2w-rMHpF"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit pyngrok torch torchvision pillow torchxrayvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZohdYk39EsI9"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import time\n",
        "import torchxrayvision as xrv\n",
        "\n",
        "st.set_page_config(page_title=\"AI Cognitive Radiology\")\n",
        "\n",
        "# ---------- YOUR LOADER CSS ----------\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        ".main-container {\n",
        "  display:flex;\n",
        "  justify-content:center;\n",
        "  align-items:center;\n",
        "  height:350px;\n",
        "}\n",
        "\n",
        ".loader {\n",
        "  width:320px;\n",
        "}\n",
        "\n",
        ".skeleton {\n",
        "  fill:#2d2d2d;\n",
        "  animation:pulse 1.8s ease-in-out infinite;\n",
        "}\n",
        "\n",
        "@keyframes pulse {\n",
        "  0%{fill:#2d2d2d;}\n",
        "  50%{fill:#505050;}\n",
        "  100%{fill:#2d2d2d;}\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "def show_startup_loader():\n",
        "    return \"\"\"\n",
        "    <div class=\"main-container\">\n",
        "        <svg class=\"loader\" viewBox=\"0 0 200 100\">\n",
        "            <rect x=\"10\" y=\"20\" width=\"180\" height=\"60\" class=\"skeleton\"/>\n",
        "            <text x=\"50%\" y=\"55%\" text-anchor=\"middle\" fill=\"#e4e4e4\" font-size=\"13\">\n",
        "                Initializing Cognitive Radiology Engine...\n",
        "            </text>\n",
        "        </svg>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "# ---------- SHOW LOADER ----------\n",
        "placeholder = st.empty()\n",
        "placeholder.markdown(show_startup_loader(), unsafe_allow_html=True)\n",
        "\n",
        "# ---------- LOAD MODEL (simulate) ----------\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    time.sleep(3)  # simulate loading\n",
        "    model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "    return model\n",
        "\n",
        "model = load_model()\n",
        "\n",
        "# ---------- REMOVE LOADER ----------\n",
        "placeholder.empty()\n",
        "\n",
        "st.success(\"AI Cognitive Radiology Engine Ready 🚀\")\n",
        "st.write(\"Now your main app will start here...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K-mjYqRoE2w5"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess, time\n",
        "\n",
        "# start streamlit\n",
        "process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\"])\n",
        "time.sleep(5)\n",
        "\n",
        "# create public link\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"OPEN THIS LINK 👉\", public_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ym-5UuZUE8vI"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio torch torchvision pillow torchxrayvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BJE_Vf5_FxYH"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "import torchxrayvision as xrv\n",
        "\n",
        "# ---------- LOAD MODEL ----------\n",
        "def load_model():\n",
        "    time.sleep(2)   # simulate startup loading\n",
        "    model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "model = load_model()\n",
        "\n",
        "\n",
        "# ---------- REPORT GENERATION ----------\n",
        "def generate_report(image):\n",
        "    time.sleep(3)   # simulate AI thinking\n",
        "\n",
        "    return \"\"\"\n",
        "FINDINGS:\n",
        "No acute cardiopulmonary abnormality. Lungs appear clear.\n",
        "\n",
        "IMPRESSION:\n",
        "Normal chest radiograph.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# ---------- UI ----------\n",
        "with gr.Blocks(title=\"AI Cognitive Radiology\") as app:\n",
        "\n",
        "    gr.Markdown(\"# 🧠 AI Cognitive Radiology Engine\")\n",
        "\n",
        "    image_input = gr.Image(type=\"pil\", label=\"Upload Chest X-ray\")\n",
        "\n",
        "    generate_btn = gr.Button(\"Generate Report\")\n",
        "\n",
        "    output_text = gr.Textbox(label=\"Radiology Report\", lines=10)\n",
        "\n",
        "    generate_btn.click(generate_report, inputs=image_input, outputs=output_text)\n",
        "\n",
        "\n",
        "# ---------- LAUNCH ----------\n",
        "app.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nSrfzCoQF2hH"
      },
      "outputs": [],
      "source": [
        "pip install matplotlib opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_bjK08rGImin"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xukMq-4gIudS"
      },
      "outputs": [],
      "source": [
        "def generate_heatmap(model, img_tensor):\n",
        "    model.eval()\n",
        "\n",
        "    # get last conv layer\n",
        "    target_layer = model.features[-1]\n",
        "\n",
        "    gradients = []\n",
        "    activations = []\n",
        "\n",
        "    def backward_hook(module, grad_in, grad_out):\n",
        "        gradients.append(grad_out[0])\n",
        "\n",
        "    def forward_hook(module, inp, out):\n",
        "        activations.append(out)\n",
        "\n",
        "    handle_fw = target_layer.register_forward_hook(forward_hook)\n",
        "    handle_bw = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    output = model(img_tensor)\n",
        "    pred_class = output.argmax()\n",
        "\n",
        "    model.zero_grad()\n",
        "    output[0, pred_class].backward()\n",
        "\n",
        "    grads = gradients[0].detach().cpu().numpy()[0]\n",
        "    acts = activations[0].detach().cpu().numpy()[0]\n",
        "\n",
        "    weights = grads.mean(axis=(1, 2))\n",
        "\n",
        "    cam = np.zeros(acts.shape[1:], dtype=np.float32)\n",
        "    for i, w in enumerate(weights):\n",
        "        cam += w * acts[i]\n",
        "\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cv2.resize(cam, (img_tensor.shape[3], img_tensor.shape[2]))\n",
        "    cam = cam - cam.min()\n",
        "    cam = cam / (cam.max() + 1e-8)\n",
        "\n",
        "    handle_fw.remove()\n",
        "    handle_bw.remove()\n",
        "\n",
        "    return cam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pkrqOSj6Iwii"
      },
      "outputs": [],
      "source": [
        "# -------- HEATMAP --------\n",
        "cam = generate_heatmap(model, img)\n",
        "\n",
        "st.subheader(\"AI Attention Heatmap\")\n",
        "\n",
        "heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "\n",
        "orig = np.array(image.resize((heatmap.shape[1], heatmap.shape[0])))\n",
        "if len(orig.shape) == 2:\n",
        "    orig = cv2.cvtColor(orig, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "overlay = cv2.addWeighted(orig, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "st.image(overlay, caption=\"Where AI looked\", use_column_width=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MaWS3AH4IztB"
      },
      "outputs": [],
      "source": [
        "\n",
        "def refine_disease_reasoning(scores):\n",
        "    # simulate medical co-occurrence reasoning\n",
        "    adjusted = scores.copy()\n",
        "\n",
        "    # Example clinical logic\n",
        "    if adjusted.get(\"Pneumonia\", 0) > 0.4:\n",
        "        adjusted[\"Consolidation\"] = max(adjusted.get(\"Consolidation\", 0), 0.35)\n",
        "\n",
        "    if adjusted.get(\"Edema\", 0) > 0.4:\n",
        "        adjusted[\"Cardiomegaly\"] = max(adjusted.get(\"Cardiomegaly\", 0), 0.3)\n",
        "\n",
        "    if adjusted.get(\"Pleural Effusion\", 0) > 0.5:\n",
        "        adjusted[\"Atelectasis\"] = max(adjusted.get(\"Atelectasis\", 0), 0.25)\n",
        "\n",
        "    # Normalize\n",
        "    total = sum(adjusted.values()) + 1e-8\n",
        "    for k in adjusted:\n",
        "        adjusted[k] = adjusted[k] / total\n",
        "\n",
        "    return adjusted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a2t00hFgJSoB"
      },
      "outputs": [],
      "source": [
        "scores = refine_disease_reasoning(scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NoyQTB0fJVLw"
      },
      "outputs": [],
      "source": [
        "NameError: name 'scores' is not defined\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Pesx8VuvJv1x"
      },
      "outputs": [],
      "source": [
        "img_t = transform(img).unsqueeze(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = model(img_t)\n",
        "\n",
        "scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "print(\"Raw Scores:\")\n",
        "for k, v in list(scores.items())[:8]:\n",
        "    print(f\"{k:20s}: {v:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZjmsKDCKJzRQ"
      },
      "outputs": [],
      "source": [
        "scores = refine_disease_reasoning(scores)\n",
        "\n",
        "print(\"\\nRefined Scores:\")\n",
        "for k, v in list(scores.items())[:8]:\n",
        "    print(f\"{k:20s}: {v:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8WMDuiH2J1Z_"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5ykWah26KPB_"
      },
      "outputs": [],
      "source": [
        "img_t = transform(img).unsqueeze(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = model(img_t)\n",
        "\n",
        "scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "print(\"Raw Scores:\")\n",
        "for k, v in list(scores.items())[:8]:\n",
        "    print(f\"{k:20s}: {v:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dgCmGRfIKRCu"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tsIJxp9cKT0O"
      },
      "outputs": [],
      "source": [
        "img_t = transform(img).unsqueeze(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = model(img_t)\n",
        "\n",
        "scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "print(\"Raw Scores:\")\n",
        "for k, v in list(scores.items())[:8]:\n",
        "    print(f\"{k:20s}: {v:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "moExI2umKWgO"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Put your test X-ray path here\n",
        "image_path = \"/root/.cache/kagglehub/datasets/raddar/chest-xrays-indiana-university/versions/2/images/CXR1_1_IM-0001-3001.png\"\n",
        "\n",
        "img = Image.open(image_path).convert(\"RGB\")\n",
        "img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4eKAVRhMK_59"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Put your test X-ray path here\n",
        "image_path = \"/root/.cache/kagglehub/datasets/raddar/chest-xrays-indiana-university/versions/2/images/CXR1_1_IM-0001-3001.png\"\n",
        "\n",
        "img = Image.open(image_path).convert(\"RGB\")\n",
        "img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DjSD5-NFLB0u"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk(path + \"/images\"):\n",
        "    for f in files[:20]:\n",
        "        print(os.path.join(root, f))\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rWg3x-7JL5M2"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"raddar/chest-xrays-indiana-university\")\n",
        "print(\"Dataset path:\", path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3JjPe722MNN8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk(path + \"/images\"):\n",
        "    for f in files[:20]:\n",
        "        print(os.path.join(root, f))\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qRwytpQwN_Iq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.listdir(path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oDRc0VVbOYsI"
      },
      "outputs": [],
      "source": [
        "for root, dirs, files in os.walk(path + \"/images\"):\n",
        "    for f in files[:1]:\n",
        "        image_path = os.path.join(root, f)\n",
        "        print(\"Using image:\", image_path)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dUrRJGffObPI"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "img = Image.open(image_path).convert(\"RGB\")\n",
        "img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FVovD6moOdgI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# search ANY png image inside dataset\n",
        "image_path = None\n",
        "for root, dirs, files in os.walk(path):\n",
        "    for f in files:\n",
        "        if f.endswith(\".png\"):\n",
        "            image_path = os.path.join(root, f)\n",
        "            break\n",
        "    if image_path:\n",
        "        break\n",
        "\n",
        "print(\"Image found:\", image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fVwMTQSqPaPX"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "img = Image.open(image_path).convert(\"RGB\")\n",
        "display(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "br4vyOlqPd0X"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "img_t = transform(img).unsqueeze(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = model(img_t)\n",
        "\n",
        "scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "for k, v in list(scores.items())[:8]:\n",
        "    print(f\"{k:20s}: {v:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nkz_r-TyPn_F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torchxrayvision as xrv\n",
        "\n",
        "# ---- Convert to grayscale numpy ----\n",
        "img_np = np.array(img.convert(\"L\"))  # force grayscale\n",
        "\n",
        "# ---- Normalize correctly for torchxrayvision ----\n",
        "img_np = xrv.datasets.normalize(img_np, 255)\n",
        "\n",
        "# ---- Convert to tensor shape (1,1,H,W) ----\n",
        "img_t = torch.from_numpy(img_np).unsqueeze(0).unsqueeze(0).float()\n",
        "\n",
        "# ---- Resize to 224 ----\n",
        "img_t = torch.nn.functional.interpolate(img_t, size=(224,224), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "# ---- Predict ----\n",
        "with torch.no_grad():\n",
        "    preds = model(img_t)\n",
        "\n",
        "# ---- Scores ----\n",
        "scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "print(\"Top Predictions:\")\n",
        "for k, v in list(scores.items())[:8]:\n",
        "    print(f\"{k:20s}: {v:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GzF_RQ3dQQaH"
      },
      "outputs": [],
      "source": [
        "import torchxrayvision as xrv\n",
        "diseases = xrv.datasets.default_pathologies\n",
        "print(\"Diseases loaded:\", len(diseases))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0H82F3teQ3pT"
      },
      "outputs": [],
      "source": [
        "# ---- Convert to grayscale numpy ----\n",
        "img_np = np.array(img.convert(\"L\"))\n",
        "\n",
        "# ---- Normalize correctly ----\n",
        "img_np = xrv.datasets.normalize(img_np, 255)\n",
        "\n",
        "# ---- Tensor shape (1,1,H,W) ----\n",
        "img_t = torch.from_numpy(img_np).unsqueeze(0).unsqueeze(0).float()\n",
        "\n",
        "# ---- Resize ----\n",
        "img_t = torch.nn.functional.interpolate(img_t, size=(224,224), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "# ---- Predict ----\n",
        "with torch.no_grad():\n",
        "    preds = model(img_t)\n",
        "\n",
        "# ---- Scores ----\n",
        "scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "print(\"Top Predictions:\")\n",
        "for k, v in list(scores.items())[:8]:\n",
        "    print(f\"{k:20s}: {v:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lCXy7GZeQ61D"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "\n",
        "def generate_heatmap(model, img_tensor):\n",
        "    model.eval()\n",
        "\n",
        "    gradients = []\n",
        "    activations = []\n",
        "\n",
        "    # last conv layer of DenseNet\n",
        "    target_layer = model.features[-1]\n",
        "\n",
        "    def forward_hook(module, inp, out):\n",
        "        activations.append(out)\n",
        "\n",
        "    def backward_hook(module, grad_in, grad_out):\n",
        "        gradients.append(grad_out[0])\n",
        "\n",
        "    h1 = target_layer.register_forward_hook(forward_hook)\n",
        "    h2 = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    output = model(img_tensor)\n",
        "    pred_class = output.argmax()\n",
        "\n",
        "    model.zero_grad()\n",
        "    output[0, pred_class].backward()\n",
        "\n",
        "    grads = gradients[0].detach().cpu().numpy()[0]\n",
        "    acts = activations[0].detach().cpu().numpy()[0]\n",
        "\n",
        "    weights = grads.mean(axis=(1,2))\n",
        "\n",
        "    cam = np.zeros(acts.shape[1:], dtype=np.float32)\n",
        "    for i, w in enumerate(weights):\n",
        "        cam += w * acts[i]\n",
        "\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cv2.resize(cam, (img_tensor.shape[3], img_tensor.shape[2]))\n",
        "    cam = cam - cam.min()\n",
        "    cam = cam / (cam.max() + 1e-8)\n",
        "\n",
        "    h1.remove()\n",
        "    h2.remove()\n",
        "\n",
        "    return cam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H2r2O15pRGwk"
      },
      "outputs": [],
      "source": [
        "cam = generate_heatmap(model, img_t)\n",
        "print(\"Heatmap generated\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q4QZ6iAxRJyE"
      },
      "outputs": [],
      "source": [
        "# convert heatmap to color\n",
        "heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "\n",
        "# original grayscale image resized\n",
        "orig = np.array(img.convert(\"L\").resize((224,224)))\n",
        "orig = cv2.cvtColor(orig, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# overlay\n",
        "overlay = cv2.addWeighted(orig, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(overlay[:,:,::-1])\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"AI Attention Heatmap\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6kdyg81pRLyT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "\n",
        "def generate_gradcam_pp(model, img_tensor):\n",
        "    model.eval()\n",
        "\n",
        "    gradients = []\n",
        "    activations = []\n",
        "\n",
        "    target_layer = model.features[-1]\n",
        "\n",
        "    def forward_hook(module, inp, out):\n",
        "        activations.append(out)\n",
        "\n",
        "    def backward_hook(module, grad_in, grad_out):\n",
        "        gradients.append(grad_out[0])\n",
        "\n",
        "    h1 = target_layer.register_forward_hook(forward_hook)\n",
        "    h2 = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    output = model(img_tensor)\n",
        "    pred_class = output.argmax()\n",
        "\n",
        "    model.zero_grad()\n",
        "    output[0, pred_class].backward(retain_graph=True)\n",
        "\n",
        "    grads = gradients[0].detach().cpu().numpy()[0]\n",
        "    acts = activations[0].detach().cpu().numpy()[0]\n",
        "\n",
        "    # Grad-CAM++ weighting\n",
        "    alpha = grads**2\n",
        "    alpha = alpha / (2 * grads**2 + np.sum(acts * grads**3, axis=(1,2), keepdims=True) + 1e-7)\n",
        "    weights = np.sum(alpha * np.maximum(grads, 0), axis=(1,2))\n",
        "\n",
        "    cam = np.zeros(acts.shape[1:], dtype=np.float32)\n",
        "    for i, w in enumerate(weights):\n",
        "        cam += w * acts[i]\n",
        "\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cv2.resize(cam, (img_tensor.shape[3], img_tensor.shape[2]))\n",
        "    cam = cam - cam.min()\n",
        "    cam = cam / (cam.max() + 1e-8)\n",
        "\n",
        "    h1.remove()\n",
        "    h2.remove()\n",
        "\n",
        "    return cam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8ZD4loBTRnz2"
      },
      "outputs": [],
      "source": [
        "cam = generate_gradcam_pp(model, img_t)\n",
        "\n",
        "heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "\n",
        "orig = np.array(img.convert(\"L\").resize((224,224)))\n",
        "orig = cv2.cvtColor(orig, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "overlay = cv2.addWeighted(orig, 0.65, heatmap, 0.35, 0)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(overlay[:,:,::-1])\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Medical Grad-CAM++ Heatmap\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YXW_bPbXRrSy"
      },
      "outputs": [],
      "source": [
        "def generate_real_clinical_report(scores, context=\"Chest X-ray study\"):\n",
        "    top = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "\n",
        "    primary = top[0][0]\n",
        "    conf = top[0][1]\n",
        "\n",
        "    findings = []\n",
        "\n",
        "    if primary.lower() == \"no finding\":\n",
        "        findings.append(\"The lungs are clear without focal consolidation, pleural effusion, or pneumothorax.\")\n",
        "        findings.append(\"Cardiomediastinal silhouette is within normal limits.\")\n",
        "    else:\n",
        "        findings.append(f\"Radiographic features suggestive of {primary.lower()} are observed.\")\n",
        "        findings.append(\"No evidence of acute life-threatening cardiopulmonary abnormality.\")\n",
        "\n",
        "    findings.append(\"Visualized osseous structures are intact.\")\n",
        "    findings.append(\"No significant interval change compared to prior study (if available).\")\n",
        "\n",
        "    impression = [\n",
        "        f\"Findings most consistent with {primary.lower()} (confidence {conf:.2f}).\",\n",
        "        \"Clinical correlation recommended.\",\n",
        "        \"Follow-up imaging may be considered based on symptoms.\"\n",
        "    ]\n",
        "\n",
        "    report = \"\\n\".join([\n",
        "        \"FINDINGS:\",\n",
        "        *findings,\n",
        "        \"\",\n",
        "        \"IMPRESSION:\",\n",
        "        *impression\n",
        "    ])\n",
        "\n",
        "    return report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8nwhou76Rt4i"
      },
      "outputs": [],
      "source": [
        "report = generate_real_clinical_report(scores)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8eqG4sAQRxXT"
      },
      "outputs": [],
      "source": [
        "def mix_mlp_reasoning(scores):\n",
        "    refined = scores.copy()\n",
        "\n",
        "    # --- Clinical co-occurrence rules ---\n",
        "\n",
        "    # Heart failure pattern\n",
        "    if refined.get(\"Edema\", 0) > 0.35 and refined.get(\"Cardiomegaly\", 0) > 0.30:\n",
        "        refined[\"Heart Failure Pattern\"] = max(refined.get(\"Heart Failure Pattern\", 0), 0.85)\n",
        "        refined[\"Edema\"] += 0.05\n",
        "        refined[\"Cardiomegaly\"] += 0.05\n",
        "\n",
        "    # Infectious pneumonia pattern\n",
        "    if refined.get(\"Consolidation\", 0) > 0.30 and refined.get(\"Pneumonia\", 0) > 0.30:\n",
        "        refined[\"Infectious Pattern\"] = 0.80\n",
        "        refined[\"Pneumonia\"] += 0.05\n",
        "\n",
        "    # Pleural disease\n",
        "    if refined.get(\"Pleural Effusion\", 0) > 0.35:\n",
        "        refined[\"Pleural Disease Pattern\"] = 0.75\n",
        "        refined[\"Atelectasis\"] = max(refined.get(\"Atelectasis\", 0), 0.30)\n",
        "\n",
        "    # Lung collapse hint\n",
        "    if refined.get(\"Atelectasis\", 0) > 0.40:\n",
        "        refined[\"Volume Loss\"] = 0.65\n",
        "\n",
        "    # --- Normalize safely ---\n",
        "    total = sum(refined.values()) + 1e-8\n",
        "    for k in refined:\n",
        "        refined[k] = refined[k] / total\n",
        "\n",
        "    return refined\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WWOUC2y_R-C0"
      },
      "outputs": [],
      "source": [
        "scores_refined = mix_mlp_reasoning(scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0IPKWo6bSAkx"
      },
      "outputs": [],
      "source": [
        "print(\"Top BEFORE reasoning:\")\n",
        "for k, v in list(scores.items())[:6]:\n",
        "    print(f\"{k:25s}: {v:.3f}\")\n",
        "\n",
        "print(\"\\nTop AFTER reasoning:\")\n",
        "top_ref = sorted(scores_refined.items(), key=lambda x: x[1], reverse=True)\n",
        "for k, v in top_ref[:6]:\n",
        "    print(f\"{k:25s}: {v:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lL2vEvFsSCZB"
      },
      "outputs": [],
      "source": [
        "report = generate_real_clinical_report(scores_refined)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u0AT7kkrSE4x"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ProFAEncoder(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone.features   # DenseNet feature extractor\n",
        "\n",
        "        # Projection heads for 3 levels\n",
        "        self.pixel_proj = nn.Conv2d(1024, 256, kernel_size=1)\n",
        "        self.region_proj = nn.Conv2d(1024, 256, kernel_size=1)\n",
        "        self.organ_proj = nn.Conv2d(1024, 256, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feat = self.backbone(x)   # shape: (B,1024,H,W)\n",
        "\n",
        "        # Pixel-level (high resolution)\n",
        "        pixel_feat = self.pixel_proj(feat)\n",
        "\n",
        "        # Region-level (medium resolution)\n",
        "        region_feat = F.avg_pool2d(feat, kernel_size=2)\n",
        "        region_feat = self.region_proj(region_feat)\n",
        "\n",
        "        # Organ-level (global)\n",
        "        organ_feat = F.adaptive_avg_pool2d(feat, (1,1))\n",
        "        organ_feat = self.organ_proj(organ_feat)\n",
        "\n",
        "        return pixel_feat, region_feat, organ_feat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m_uj0ob2Se7x"
      },
      "outputs": [],
      "source": [
        "profa = ProFAEncoder(model).eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uYo0lrB8ShHB"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    pixel_feat, region_feat, organ_feat = profa(img_t)\n",
        "\n",
        "print(\"Pixel-level feature:\", pixel_feat.shape)\n",
        "print(\"Region-level feature:\", region_feat.shape)\n",
        "print(\"Organ-level feature:\", organ_feat.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-Dgtwc6sSjEi"
      },
      "outputs": [],
      "source": [
        "def fuse_profa(pixel, region, organ):\n",
        "    pixel_vec = pixel.mean(dim=[2,3])\n",
        "    region_vec = region.mean(dim=[2,3])\n",
        "    organ_vec = organ.view(organ.size(0), -1)\n",
        "\n",
        "    fused = torch.cat([pixel_vec, region_vec, organ_vec], dim=1)\n",
        "    return fused\n",
        "\n",
        "fused_feature = fuse_profa(pixel_feat, region_feat, organ_feat)\n",
        "print(\"Fused cognitive feature:\", fused_feature.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vjhW2tYZSlzg"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class RCTA(nn.Module):\n",
        "    def __init__(self, feat_dim, label_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # Attention layers\n",
        "        self.image_to_context = nn.Linear(feat_dim, feat_dim)\n",
        "        self.context_to_label = nn.Linear(feat_dim, label_dim)\n",
        "        self.label_to_image = nn.Linear(label_dim, feat_dim)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, img_feat, context_vec, label_vec):\n",
        "\n",
        "        # Stage 1: Image queries Context\n",
        "        ctx_attention = self.activation(self.image_to_context(img_feat))\n",
        "        ctx_out = ctx_attention + context_vec\n",
        "\n",
        "        # Stage 2: Context queries Labels (Hypothesis)\n",
        "        label_attention = self.activation(self.context_to_label(ctx_out))\n",
        "        label_out = label_attention + label_vec\n",
        "\n",
        "        # Stage 3: Labels verify Image (Closed loop)\n",
        "        img_attention = self.activation(self.label_to_image(label_out))\n",
        "        verified_img = img_attention + img_feat\n",
        "\n",
        "        return verified_img, label_out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rreX7ru2S2YA"
      },
      "outputs": [],
      "source": [
        "# Simple simulated context embedding\n",
        "context_vec = torch.randn(1, fused_feature.shape[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z2i9CgHpS6jR"
      },
      "outputs": [],
      "source": [
        "label_values = list(scores_refined.values())[:len(diseases)]\n",
        "label_vec = torch.tensor(label_values).unsqueeze(0).float()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xM5wiC7DS8qQ"
      },
      "outputs": [],
      "source": [
        "rcta = RCTA(feat_dim=fused_feature.shape[1], label_dim=label_vec.shape[1]).eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    verified_img_feat, updated_labels = rcta(fused_feature, context_vec, label_vec)\n",
        "\n",
        "print(\"Verified image feature:\", verified_img_feat.shape)\n",
        "print(\"Updated label hypothesis:\", updated_labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PROpjLyPS_tg"
      },
      "outputs": [],
      "source": [
        "def cognitive_radiology_inference(img, model, profa, rcta):\n",
        "    # ---------------------------\n",
        "    # 1. Preprocess image\n",
        "    # ---------------------------\n",
        "    import numpy as np\n",
        "    import torchxrayvision as xrv\n",
        "    import torch\n",
        "\n",
        "    img_np = np.array(img.convert(\"L\"))\n",
        "    img_np = xrv.datasets.normalize(img_np, 255)\n",
        "    img_t = torch.from_numpy(img_np).unsqueeze(0).unsqueeze(0).float()\n",
        "    img_t = torch.nn.functional.interpolate(img_t, size=(224,224), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "    # ---------------------------\n",
        "    # 2. Base prediction\n",
        "    # ---------------------------\n",
        "    with torch.no_grad():\n",
        "        preds = model(img_t)\n",
        "\n",
        "    base_scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "\n",
        "    # ---------------------------\n",
        "    # 3. MIX-MLP reasoning\n",
        "    # ---------------------------\n",
        "    refined_scores = mix_mlp_reasoning(base_scores)\n",
        "\n",
        "    # ---------------------------\n",
        "    # 4. PRO-FA hierarchical vision\n",
        "    # ---------------------------\n",
        "    with torch.no_grad():\n",
        "        pixel_feat, region_feat, organ_feat = profa(img_t)\n",
        "\n",
        "    fused_feature = fuse_profa(pixel_feat, region_feat, organ_feat)\n",
        "\n",
        "    # ---------------------------\n",
        "    # 5. Create context + label vectors\n",
        "    # ---------------------------\n",
        "    context_vec = torch.randn(1, fused_feature.shape[1])\n",
        "\n",
        "    label_values = list(refined_scores.values())[:len(diseases)]\n",
        "    label_vec = torch.tensor(label_values).unsqueeze(0).float()\n",
        "\n",
        "    # ---------------------------\n",
        "    # 6. RCTA Cognitive Loop\n",
        "    # ---------------------------\n",
        "    with torch.no_grad():\n",
        "        verified_img_feat, updated_labels = rcta(fused_feature, context_vec, label_vec)\n",
        "\n",
        "    # ---------------------------\n",
        "    # 7. Generate Clinical Report\n",
        "    # ---------------------------\n",
        "    report = generate_real_clinical_report(refined_scores)\n",
        "\n",
        "    return refined_scores, report, img_t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NszIuQl9U6Tv"
      },
      "outputs": [],
      "source": [
        "scores_final, final_report, img_t = cognitive_radiology_inference(img, model, profa, rcta)\n",
        "\n",
        "print(\"FINAL REPORT:\\n\")\n",
        "print(final_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "71L3ztS9U-Es"
      },
      "outputs": [],
      "source": [
        "cam = generate_gradcam_pp(model, img_t)\n",
        "\n",
        "heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "\n",
        "orig = np.array(img.convert(\"L\").resize((224,224)))\n",
        "orig = cv2.cvtColor(orig, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "overlay = cv2.addWeighted(orig, 0.65, heatmap, 0.35, 0)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(overlay[:,:,::-1])\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Cognitive AI Attention\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jTDDUMPeVAoM"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchxrayvision as xrv\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "st.set_page_config(page_title=\"Cognitive Radiology AI\", layout=\"wide\")\n",
        "\n",
        "# ------------------ STYLING ------------------\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "body {background-color: #0e1117;}\n",
        "h1, h2, h3 {color: #e6edf3;}\n",
        ".report-box {\n",
        "    background-color: #161b22;\n",
        "    padding: 20px;\n",
        "    border-radius: 10px;\n",
        "    border: 1px solid #30363d;\n",
        "    color: #c9d1d9;\n",
        "}\n",
        ".metric-box {\n",
        "    background-color: #161b22;\n",
        "    padding: 10px;\n",
        "    border-radius: 8px;\n",
        "    border: 1px solid #30363d;\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.title(\"🧠 Cognitive Radiology AI\")\n",
        "st.caption(\"Hierarchical Vision • Clinical Reasoning • Cognitive Attention\")\n",
        "\n",
        "# ------------------ LOAD MODEL ------------------\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "model = load_model()\n",
        "diseases = xrv.datasets.default_pathologies\n",
        "\n",
        "# ------------------ UPLOAD ------------------\n",
        "uploaded = st.file_uploader(\"Upload Chest X-ray\", type=[\"png\",\"jpg\",\"jpeg\"])\n",
        "\n",
        "if uploaded:\n",
        "    col1, col2 = st.columns([1,1])\n",
        "\n",
        "    img = Image.open(uploaded).convert(\"RGB\")\n",
        "    col1.image(img, caption=\"Input X-ray\", use_column_width=True)\n",
        "\n",
        "    # -------- PREPROCESS --------\n",
        "    img_np = np.array(img.convert(\"L\"))\n",
        "    img_np = xrv.datasets.normalize(img_np, 255)\n",
        "    img_t = torch.from_numpy(img_np).unsqueeze(0).unsqueeze(0).float()\n",
        "    img_t = torch.nn.functional.interpolate(img_t, size=(224,224))\n",
        "\n",
        "    # -------- PREDICT --------\n",
        "    with torch.no_grad():\n",
        "        preds = model(img_t)\n",
        "\n",
        "    scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "    scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "    # ------------------ HEATMAP ------------------\n",
        "    st.subheader(\"AI Visual Attention\")\n",
        "\n",
        "    gradients = []\n",
        "    activations = []\n",
        "\n",
        "    target_layer = model.features[-1]\n",
        "\n",
        "    def f_hook(module, inp, out): activations.append(out)\n",
        "    def b_hook(module, gin, gout): gradients.append(gout[0])\n",
        "\n",
        "    h1 = target_layer.register_forward_hook(f_hook)\n",
        "    h2 = target_layer.register_backward_hook(b_hook)\n",
        "\n",
        "    output = model(img_t)\n",
        "    cls = output.argmax()\n",
        "    model.zero_grad()\n",
        "    output[0, cls].backward()\n",
        "\n",
        "    grads = gradients[0].detach().cpu().numpy()[0]\n",
        "    acts = activations[0].detach().cpu().numpy()[0]\n",
        "\n",
        "    weights = grads.mean(axis=(1,2))\n",
        "    cam = np.zeros(acts.shape[1:], dtype=np.float32)\n",
        "    for i, w in enumerate(weights):\n",
        "        cam += w * acts[i]\n",
        "\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cv2.resize(cam, (224,224))\n",
        "    cam = cam / (cam.max()+1e-8)\n",
        "\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET)\n",
        "    base = np.array(img.convert(\"L\").resize((224,224)))\n",
        "    base = cv2.cvtColor(base, cv2.COLOR_GRAY2BGR)\n",
        "    overlay = cv2.addWeighted(base, 0.65, heatmap, 0.35, 0)\n",
        "\n",
        "    col2.image(overlay[:,:,::-1], caption=\"Model Attention\")\n",
        "\n",
        "    # ------------------ METRICS ------------------\n",
        "    st.subheader(\"Top Clinical Predictions\")\n",
        "\n",
        "    cols = st.columns(3)\n",
        "    for i, (k,v) in enumerate(list(scores.items())[:6]):\n",
        "        cols[i%3].metric(k, f\"{v:.3f}\")\n",
        "\n",
        "    # ------------------ REPORT ------------------\n",
        "    primary = list(scores.items())[0]\n",
        "\n",
        "    report = f\"\"\"\n",
        "FINDINGS:\n",
        "Radiographic appearance suggests **{primary[0]}**.\n",
        "No acute life-threatening cardiopulmonary abnormality identified.\n",
        "Cardiomediastinal silhouette within acceptable limits.\n",
        "\n",
        "IMPRESSION:\n",
        "Findings most consistent with **{primary[0]}** (confidence {primary[1]:.2f}).\n",
        "Clinical correlation recommended.\n",
        "\"\"\"\n",
        "\n",
        "    st.subheader(\"AI Generated Radiology Report\")\n",
        "    st.markdown(f\"<div class='report-box'>{report}</div>\", unsafe_allow_html=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C55qA1J1VvI7"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit torch torchvision pillow torchxrayvision matplotlib opencv-python pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "89YHgX1xVyHs"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess, time\n",
        "\n",
        "process = subprocess.Popen([\"streamlit\",\"run\",\"app.py\",\"--server.port=8501\"])\n",
        "time.sleep(5)\n",
        "print(ngrok.connect(8501))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZtqG2uikV3EL"
      },
      "outputs": [],
      "source": [
        "!npm install -g localtunnel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ehk8Oir2WMR6"
      },
      "outputs": [],
      "source": [
        "import subprocess, time\n",
        "\n",
        "process = subprocess.Popen([\"streamlit\",\"run\",\"app.py\",\"--server.port=8501\"])\n",
        "time.sleep(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KX8_VzbWWO-r"
      },
      "outputs": [],
      "source": [
        "!lt --port 8501\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vC1iK-ezWQ_7"
      },
      "outputs": [],
      "source": [
        "!curl ipv4.icanhazip.com\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z9x_njq7WaFa"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio torch torchvision pillow torchxrayvision matplotlib opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ISDsiAEn1FX5"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchxrayvision as xrv\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------- Load Model ----------\n",
        "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "model.eval()\n",
        "diseases = xrv.datasets.default_pathologies\n",
        "\n",
        "\n",
        "# ---------- Heatmap ----------\n",
        "def generate_heatmap(img_t):\n",
        "    gradients = []\n",
        "    activations = []\n",
        "\n",
        "    target_layer = model.features[-1]\n",
        "\n",
        "    def f_hook(module, inp, out):\n",
        "        activations.append(out)\n",
        "\n",
        "    def b_hook(module, gin, gout):\n",
        "        gradients.append(gout[0])\n",
        "\n",
        "    h1 = target_layer.register_forward_hook(f_hook)\n",
        "    h2 = target_layer.register_backward_hook(b_hook)\n",
        "\n",
        "    output = model(img_t)\n",
        "    cls = output.argmax()\n",
        "    model.zero_grad()\n",
        "    output[0, cls].backward()\n",
        "\n",
        "    grads = gradients[0].detach().cpu().numpy()[0]\n",
        "    acts = activations[0].detach().cpu().numpy()[0]\n",
        "\n",
        "    weights = grads.mean(axis=(1,2))\n",
        "    cam = np.zeros(acts.shape[1:], dtype=np.float32)\n",
        "    for i, w in enumerate(weights):\n",
        "        cam += w * acts[i]\n",
        "\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cv2.resize(cam, (224,224))\n",
        "    cam = cam / (cam.max()+1e-8)\n",
        "\n",
        "    h1.remove()\n",
        "    h2.remove()\n",
        "    return cam\n",
        "\n",
        "\n",
        "# ---------- Main Function ----------\n",
        "def analyze_xray(image):\n",
        "\n",
        "    img = image.convert(\"L\")\n",
        "    img_np = np.array(img)\n",
        "    img_np = xrv.datasets.normalize(img_np, 255)\n",
        "    img_t = torch.from_numpy(img_np).unsqueeze(0).unsqueeze(0).float()\n",
        "    img_t = torch.nn.functional.interpolate(img_t, size=(224,224))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model(img_t)\n",
        "\n",
        "    scores = {diseases[i]: float(preds[0][i]) for i in range(len(diseases))}\n",
        "    scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "    # Heatmap\n",
        "    cam = generate_heatmap(img_t)\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET)\n",
        "\n",
        "    base = np.array(img.resize((224,224)))\n",
        "    base = cv2.cvtColor(base, cv2.COLOR_GRAY2BGR)\n",
        "    overlay = cv2.addWeighted(base, 0.65, heatmap, 0.35, 0)\n",
        "\n",
        "    # Report\n",
        "    primary = list(scores.items())[0]\n",
        "    report = f\"\"\"\n",
        "FINDINGS:\n",
        "Radiographic appearance suggests {primary[0]}.\n",
        "No acute life-threatening abnormality detected.\n",
        "\n",
        "IMPRESSION:\n",
        "Most consistent with {primary[0]} (confidence {primary[1]:.2f}).\n",
        "Clinical correlation recommended.\n",
        "\"\"\"\n",
        "\n",
        "    top_text = \"\\n\".join([f\"{k}: {v:.3f}\" for k,v in list(scores.items())[:6]])\n",
        "\n",
        "    return overlay[:,:,::-1], top_text, report\n",
        "\n",
        "\n",
        "# ---------- UI ----------\n",
        "demo = gr.Interface(\n",
        "    fn=analyze_xray,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Upload Chest X-ray\"),\n",
        "    outputs=[\n",
        "        gr.Image(label=\"AI Attention Heatmap\"),\n",
        "        gr.Textbox(label=\"Top Predictions\"),\n",
        "        gr.Textbox(label=\"Radiology Report\")\n",
        "    ],\n",
        "    title=\"🧠 Cognitive Radiology AI\",\n",
        "    description=\"Hierarchical Vision • Clinical Reasoning • Cognitive Attention\",\n",
        ")\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iRKuKh1z1Goo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------- Grad-CAM --------\n",
        "def generate_gradcam(model, img_tensor, target_index=0):\n",
        "    model.eval()\n",
        "\n",
        "    gradients = []\n",
        "    activations = []\n",
        "\n",
        "    def backward_hook(module, grad_in, grad_out):\n",
        "        gradients.append(grad_out[0])\n",
        "\n",
        "    def forward_hook(module, inp, out):\n",
        "        activations.append(out)\n",
        "\n",
        "    # Hook last conv layer\n",
        "    target_layer = model.features[-1]\n",
        "    handle_f = target_layer.register_forward_hook(forward_hook)\n",
        "    handle_b = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    output = model(img_tensor)\n",
        "    score = output[0, target_index]\n",
        "    model.zero_grad()\n",
        "    score.backward()\n",
        "\n",
        "    grads = gradients[0]\n",
        "    acts = activations[0]\n",
        "\n",
        "    weights = torch.mean(grads, dim=(2, 3), keepdim=True)\n",
        "    cam = torch.sum(weights * acts, dim=1).squeeze()\n",
        "    cam = F.relu(cam)\n",
        "\n",
        "    cam = cam.detach().cpu().numpy()\n",
        "    cam = cv2.resize(cam, (224, 224))\n",
        "    cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
        "\n",
        "    handle_f.remove()\n",
        "    handle_b.remove()\n",
        "\n",
        "    return cam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ep4SR9GAmFLO"
      },
      "outputs": [],
      "source": [
        "def show_heatmap_on_image(img, cam):\n",
        "    img_np = np.array(img.resize((224, 224)).convert(\"RGB\"))\n",
        "\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "    overlay = cv2.addWeighted(img_np, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(overlay)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"AI Attention Heatmap (Grad-CAM)\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hauRgKLlmK4p"
      },
      "outputs": [],
      "source": [
        "top_disease_index = np.argmax(preds.detach().cpu().numpy())\n",
        "cam = generate_gradcam(model, img_t, top_disease_index)\n",
        "show_heatmap_on_image(img, cam)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CKLfXUN1mNvP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.save(model.state_dict(), \"model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lcFXvpm-6zAq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}